{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1N87P9YfZMt3xDzC7fuuUwYs6FtpKSePD",
      "authorship_tag": "ABX9TyOjnKnpZYZCmyMJOPcwpAtg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kessandra1/AER850_Project3/blob/main/project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 0: INTRODUCTION\n",
        "\n",
        "# Install Ultralytics (for YOLOv11), OpenCV, Matplotlib, numpy, and Pillow\n",
        "!pip install -q ultralytics --upgrade\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q matplotlib\n",
        "!pip install -q numpy\n",
        "!pip install -q pillow\n",
        "\n",
        "# Import\n",
        "import os\n",
        "import zipfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Extract Project 3 Data zip folder\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/Project 3 Data.zip'\n",
        "extract_path = '/content/project3_data'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "74XSVIKm0whB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: OBJECT MASKING\n",
        "\n",
        "# Load Motherboard JPEG image\n",
        "img_path = os.path.join(extract_path, 'Project 3 Data', 'motherboard_image.JPEG')\n",
        "img = cv2.imread(img_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert image to grayscale for easier thresholding\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Perform thresholding with OpenCV\n",
        "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "# EDGE DETECTION using Contour detector (Canny) & Contour detection\n",
        "edges = cv2.Canny(gray, 125, 225)\n",
        "edges_dilated = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=2)\n",
        "contours = cv2.findContours(edges_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "plt.imshow(edges_dilated, cmap='gray')\n",
        "plt.title(\"Edges Detected\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "#Create a mask\n",
        "largest_contour = max(contours, key=cv2.contourArea)\n",
        "mask = np.zeros_like(gray)\n",
        "cv2.drawContours(mask, [largest_contour], -1, 255, -1)\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.title(\"Mask Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "#Extract PCB using cv2.bitwise_and() operator\n",
        "pcb_extracted = cv2.bitwise_and(img, img, mask=mask)\n",
        "plt.imshow(cv2.cvtColor(pcb_extracted, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Extracted Motherboard Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lXgBiFujJyni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: YOLOV11 TRAINING\n",
        "\n",
        "# Extract data zip folder that is inside Project 3 Data zip folder\n",
        "data_zip = os.path.join(extract_path, 'Project 3 Data', 'data.zip')\n",
        "data_dir = '/content/project3_data/data'\n",
        "with zipfile.ZipFile(data_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "\n",
        "# Path to data.yaml\n",
        "data_yaml = '/content/project3_data/data/data/data.yaml'\n",
        "\n",
        "# YOLOv11 Nano pretrained model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Fine-tune model\n",
        "history = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=100,       # <200\n",
        "    batch=32,\n",
        "    imgsz=1200,      # â‰¥900\n",
        "    name=\"mdl\"\n",
        ")"
      ],
      "metadata": {
        "id": "Ty7n_Z2RkFW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: EVALUATION\n",
        "\n",
        "# Get all images to be evaluated\n",
        "evaluation_images = [\n",
        "    \"/content/project3_data/data/data/evaluation/arduno.jpg\",\n",
        "    \"/content/project3_data/data/data/evaluation/ardmega.jpg\",\n",
        "    \"/content/project3_data/data/data/evaluation/rasppi.jpg\"\n",
        "]\n",
        "\n",
        "# Loop over each evaluation image and show predictions with bounding boxes\n",
        "for img_file in evaluation_images:\n",
        "    result = model.predict(img_file, conf=0.5)[0]  # take the first (and only) result\n",
        "    result.show()\n"
      ],
      "metadata": {
        "id": "xIG5TdIDHnRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}